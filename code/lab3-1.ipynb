{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c3c6ef83-9d06-4e68-a413-d2c8abfdd3f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26573af7-9673-4df6-ac99-f255ca4e9a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'subject2', 'subject3', 'raw_text.pkl']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path = \"/ocean/projects/mth240012p/shared/data\"\n",
    "print(os.listdir(data_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83991764-bd2c-430c-b8c5-a3bdf1606f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stumblinginthedark.npy', 'singlewomanseekingmanwich.npy', 'theclosetthatateeverything.npy', 'jugglingandjesus.npy', 'threemonths.npy', 'escapingfromadirediagnosis.npy', 'wildwomenanddancingqueens.npy', 'igrewupinthewestborobaptistchurch.npy', 'undertheinfluence.npy', 'quietfire.npy', 'exorcism.npy', 'sweetaspie.npy', 'becomingindian.npy', 'whenmothersbullyback.npy', 'superheroesjustforeachother.npy', 'againstthewind.npy', 'indianapolis.npy', 'goingthelibertyway.npy', 'theshower.npy', 'bluehope.npy', 'adventuresinsayingyes.npy', 'seedpotatoesofleningrad.npy', 'lifereimagined.npy', 'backsideofthestorm.npy', 'thepostmanalwayscalls.npy', 'itsabox.npy', 'catfishingstrangerstofindmyself.npy', 'waitingtogo.npy', 'afearstrippedbare.npy', 'odetostepfather.npy', 'christmas1940.npy', 'haveyoumethimyet.npy', 'tildeath.npy', 'lifeanddeathontheoregontrail.npy', 'hangtime.npy', 'reachingoutbetweenthebars.npy', 'cocoonoflove.npy', 'findingmyownrescuer.npy', 'naked.npy', 'fromboyhoodtofatherhood.npy', 'theadvancedbeginner.npy', 'food.npy', 'gangstersandcookies.npy', 'souls.npy', 'goldiethegoldfish.npy', 'lawsthatchokecreativity.npy', 'mayorofthefreaks.npy', 'howtodraw.npy', 'cautioneating.npy', 'mybackseatviewofagreatromance.npy', 'treasureisland.npy', 'golfclubbing.npy', 'beneaththemushroomcloud.npy', 'googlingstrangersandkentuckybluegrass.npy', 'marryamanwholoveshismother.npy', 'inamoment.npy', 'thefreedomridersandme.npy', 'firetestforlove.npy', 'thecurse.npy', 'myfathershands.npy', 'swimmingwithastronauts.npy', 'breakingupintheageofgoogle.npy', 'forgettingfear.npy', 'afatherscover.npy', 'thesecrettomarriage.npy', 'ifthishaircouldtalk.npy', 'comingofageondeathrow.npy', 'avatar.npy', 'canadageeseandddp.npy', 'wheretheressmoke.npy', 'tetris.npy', 'kiksuya.npy', 'leavingbaghdad.npy', 'legacy.npy', 'adollshouse.npy', 'buck.npy', 'listo.npy', 'life.npy', 'metsmagic.npy', 'alternateithicatom.npy', 'theinterview.npy', 'whyimustspeakoutaboutclimatechange.npy', 'thumbsup.npy', 'shoppinginchina.npy', 'stagefright.npy', 'thetriangleshirtwaistconnection.npy', 'onapproachtopluto.npy', 'sloth.npy', 'vixenandtheussr.npy', 'thesurprisingthingilearnedsailingsoloaroundtheworld.npy', 'thetiniestbouquet.npy', 'gpsformylostidentity.npy', 'eyespy.npy', 'learninghumanityfromdogs.npy', 'canplanetearthfeedtenbillionpeoplepart1.npy', 'birthofanation.npy', 'canplanetearthfeedtenbillionpeoplepart2.npy', 'notontheusualtour.npy', 'canplanetearthfeedtenbillionpeoplepart3.npy', 'thatthingonmyarm.npy', 'penpal.npy']\n"
     ]
    }
   ],
   "source": [
    "subject2_path = os.path.join(data_path, \"subject2\")\n",
    "print(os.listdir(subject2_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f96e07-ecb5-49eb-bf74-ff26a5214539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stumblinginthedark.npy', 'singlewomanseekingmanwich.npy', 'theclosetthatateeverything.npy', 'jugglingandjesus.npy', 'threemonths.npy', 'escapingfromadirediagnosis.npy', 'wildwomenanddancingqueens.npy', 'igrewupinthewestborobaptistchurch.npy', 'undertheinfluence.npy', 'quietfire.npy', 'exorcism.npy', 'sweetaspie.npy', 'becomingindian.npy', 'whenmothersbullyback.npy', 'superheroesjustforeachother.npy', 'againstthewind.npy', 'indianapolis.npy', 'goingthelibertyway.npy', 'theshower.npy', 'bluehope.npy', 'adventuresinsayingyes.npy', 'seedpotatoesofleningrad.npy', 'lifereimagined.npy', 'backsideofthestorm.npy', 'thepostmanalwayscalls.npy', 'itsabox.npy', 'catfishingstrangerstofindmyself.npy', 'waitingtogo.npy', 'afearstrippedbare.npy', 'odetostepfather.npy', 'christmas1940.npy', 'haveyoumethimyet.npy', 'tildeath.npy', 'lifeanddeathontheoregontrail.npy', 'hangtime.npy', 'reachingoutbetweenthebars.npy', 'cocoonoflove.npy', 'findingmyownrescuer.npy', 'naked.npy', 'fromboyhoodtofatherhood.npy', 'theadvancedbeginner.npy', 'food.npy', 'gangstersandcookies.npy', 'souls.npy', 'goldiethegoldfish.npy', 'lawsthatchokecreativity.npy', 'mayorofthefreaks.npy', 'howtodraw.npy', 'cautioneating.npy', 'mybackseatviewofagreatromance.npy', 'treasureisland.npy', 'golfclubbing.npy', 'beneaththemushroomcloud.npy', 'googlingstrangersandkentuckybluegrass.npy', 'marryamanwholoveshismother.npy', 'inamoment.npy', 'thefreedomridersandme.npy', 'firetestforlove.npy', 'thecurse.npy', 'myfathershands.npy', 'swimmingwithastronauts.npy', 'breakingupintheageofgoogle.npy', 'forgettingfear.npy', 'afatherscover.npy', 'thesecrettomarriage.npy', 'ifthishaircouldtalk.npy', 'comingofageondeathrow.npy', 'avatar.npy', 'canadageeseandddp.npy', 'wheretheressmoke.npy', 'tetris.npy', 'kiksuya.npy', 'leavingbaghdad.npy', 'legacy.npy', 'adollshouse.npy', 'buck.npy', 'listo.npy', 'life.npy', 'metsmagic.npy', 'alternateithicatom.npy', 'theinterview.npy', 'whyimustspeakoutaboutclimatechange.npy', 'thumbsup.npy', 'shoppinginchina.npy', 'stagefright.npy', 'thetriangleshirtwaistconnection.npy', 'onapproachtopluto.npy', 'sloth.npy', 'vixenandtheussr.npy', 'thesurprisingthingilearnedsailingsoloaroundtheworld.npy', 'thetiniestbouquet.npy', 'gpsformylostidentity.npy', 'eyespy.npy', 'learninghumanityfromdogs.npy', 'canplanetearthfeedtenbillionpeoplepart1.npy', 'birthofanation.npy', 'canplanetearthfeedtenbillionpeoplepart2.npy', 'notontheusualtour.npy', 'canplanetearthfeedtenbillionpeoplepart3.npy', 'thatthingonmyarm.npy', 'penpal.npy']\n"
     ]
    }
   ],
   "source": [
    "subject3_path = os.path.join(data_path, \"subject3\")\n",
    "print(os.listdir(subject3_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91827acd-7036-4de2-b929-12598934ef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of raw_text: <class 'dict'>\n",
      "Sample of raw_text: [('sweetaspie', <ridge_utils.DataSequence.DataSequence object at 0x14f5362a29e0>), ('thatthingonmyarm', <ridge_utils.DataSequence.DataSequence object at 0x14f5362a3e00>)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_37798/2984410100.py:5: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  raw_text = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "raw_text_path = os.path.join(data_path, \"raw_text.pkl\")\n",
    "with open(raw_text_path, 'rb') as f:\n",
    "    raw_text = pickle.load(f)\n",
    "\n",
    "# Inspect the type and structure of raw_text\n",
    "print(\"Type of raw_text:\", type(raw_text))\n",
    "print(\"Sample of raw_text:\", list(raw_text.items())[:2] if isinstance(raw_text, dict) else raw_text[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e32dbb5-63ef-468d-862d-af11336e7993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y for subject2, story1: (489, 94251)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example path (adjust based on the actual file name from os.listdir(subject2_path))\n",
    "bold_path = os.path.join(subject2_path, \"stumblinginthedark.npy\")\n",
    "Y = np.load(bold_path)\n",
    "\n",
    "# Check the shape of Y\n",
    "print(\"Shape of Y for subject2, story1:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e63f9a-02d7-4944-9e8b-2c3900dc8385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stories for subject2: 101\n",
      "First 5 stories: ['stumblinginthedark', 'singlewomanseekingmanwich', 'theclosetthatateeverything', 'jugglingandjesus', 'threemonths']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path = \"/ocean/projects/mth240012p/shared/data\"\n",
    "subject2_path = os.path.join(data_path, \"subject2\")\n",
    "story_files = os.listdir(subject2_path)\n",
    "stories = [f.replace('.npy', '') for f in story_files if f.endswith('.npy')]\n",
    "print(\"Total stories for subject2:\", len(stories))\n",
    "print(\"First 5 stories:\", stories[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab54ac40-2333-498f-8061-8a6bc98041fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training stories: 80\n",
      "Training stories: ['thesurprisingthingilearnedsailingsoloaroundtheworld', 'catfishingstrangerstofindmyself', 'gangstersandcookies', 'tetris', 'againstthewind']\n",
      "Number of test stories: 21\n",
      "Test stories: ['stagefright', 'inamoment', 'comingofageondeathrow', 'avatar', 'lawsthatchokecreativity']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the stories\n",
    "train_stories, test_stories = train_test_split(stories, test_size=0.2, random_state=42)\n",
    "print(\"Number of training stories:\", len(train_stories))\n",
    "print(\"Training stories:\", train_stories[:5])\n",
    "print(\"Number of test stories:\", len(test_stories))\n",
    "print(\"Test stories:\", test_stories[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3914418-6733-479c-9bce-7bb11c52cbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample DataSequence attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__firstlineno__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', 'chunk_to_data_ind', 'chunkmeans', 'chunks', 'chunksums', 'copy', 'data', 'data_times', 'data_to_chunk_ind', 'from_chunks', 'from_grid', 'mapdata', 'split_inds', 'tr_times']\n",
      "Sample text snippet: ['', 'i', 'embarked', 'on', 'a', 'journey', 'toward', 'the', 'sea', 'of', 'matrimony', 'at', 'the', 'perilous', 'age', 'of', 'forty', 'one', 'yeah', \"you'd\", 'think', 'forty', 'one', 'a', 'trip', 'to', 'marriage', 'would', 'be', 'pretty', 'smooth', 'but', 'nobody', 'had', 'told', 'my', 'family', 'my', 'sister', 'called', 'me', 'up', 'and', 'she', 'said', 'you', 'have', 'to', 'order', 'engraved', 'invitations', 'i', 'said', 'i', \"don't\", 'think', 'so', \"we're\", 'having', 'a', 'potluck', 'she', 'called', 'again', 'people', 'are', 'asking', 'me', 'what', 'to', 'get', 'you', 'for', 'a', 'wedding', 'present', 'you', 'have', 'to', 'register', 'at', 'stores', 'i', 'said', 'i', \"don't\", 'think', 'so', \"we're\", 'combining', 'two', 'apartments', \"we've\", 'got', 'so', 'many', 'duplicates', \"we're\", 'trying', 'to', 'figure', 'out', 'what', 'to', 'give', 'away', 'but', 'they', 'want', 'to', 'give', 'you', 'presents', 'she', 'said', 'we', 'know', \"that's\", 'why', \"we're\", 'having', 'a', 'potluck', 'they', 'can', 'all', 'bring', 'food', 'our', 'simple', 'invitations', 'went', 'out', 'and', 'i', 'received', 'a', 'phone', 'call', 'from', 'one', 'of', 'my', 'aunts', \"i'm\", 'looking', 'at', 'your', 'invitation', 'she', 'said', 'and', 'i', 'see', 'this', 'thing', 'about', 'bringing', 'a', 'dish', 'for', 'the', 'potluck', 'and', \"i'm\", 'wondering', 'is', 'the', 'is', 'the', 'dish', 'supposed', 'to', 'be', 'your', 'wedding', 'present', 'no', 'no', \"it's\", 'an', 'ordinary', 'potluck', 'you', 'bring', 'the', 'food', 'take', 'your', 'dish', 'home', \"it's\", 'just', 'a', 'potluck', 'my', 'mother', 'developed', 'this', 'obsession']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_37798/771069617.py:5: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  raw_text = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "raw_text_path = os.path.join(data_path, \"raw_text.pkl\")\n",
    "with open(raw_text_path, 'rb') as f:\n",
    "    raw_text = pickle.load(f)\n",
    "\n",
    "# Inspect the DataSequence object for the first story\n",
    "sample_story = list(raw_text.keys())[0]\n",
    "sample_data = raw_text[sample_story]\n",
    "print(\"Sample DataSequence attributes:\", dir(sample_data))\n",
    "\n",
    "# Try to access the text (common attribute might be 'text' or 'data')\n",
    "try:\n",
    "    sample_text = sample_data.text if hasattr(sample_data, 'text') else sample_data.data\n",
    "    print(\"Sample text snippet:\", sample_text[:200])\n",
    "except AttributeError:\n",
    "    print(\"Could not access text directly. Check ridge_utils documentation or ask your instructor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c9b6913-5281-4702-bf3a-f89f93206789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of sample_data.data: <class 'list'>\n",
      "First 10 elements of sample_data.data: ['', 'when', \"you're\", 'a', 'child', 'anything', 'and', 'everything', 'is', 'possible']\n"
     ]
    }
   ],
   "source": [
    "# Inspect the 'data' attribute of the first training story\n",
    "sample_story = train_stories[0]  # e.g., 'thesurprisingthingilearnedsailingsoloaroundtheworld'\n",
    "sample_data = raw_text[sample_story]\n",
    "sample_data_content = sample_data.data  # Try accessing the data attribute\n",
    "print(\"Type of sample_data.data:\", type(sample_data_content))\n",
    "print(\"First 10 elements of sample_data.data:\", sample_data_content[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df741e02-5487-4c44-bc9c-9b7df4df0e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text snippet: when you're a child anything and everything is possible the challenge so often is hanging on to that as we grow up and as a four year old i had the opportunity to sail for the first time i will never \n"
     ]
    }
   ],
   "source": [
    "# Attempt to convert data to text\n",
    "if isinstance(sample_data_content, str):\n",
    "    sample_text = sample_data_content\n",
    "elif isinstance(sample_data_content, (list, np.ndarray)):\n",
    "    sample_text = ' '.join(str(item) for item in sample_data_content if item)  # Handle empty or None\n",
    "else:\n",
    "    raise ValueError(\"Unexpected data type in DataSequence.data. Check documentation or ask instructor.\")\n",
    "\n",
    "print(\"Sample text snippet:\", sample_text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62133e29-0e27-48ec-82b2-ec1585ab1ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of BoW matrix: (80, 10658)\n",
      "Vocabulary size: 10658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Extract text for training stories\n",
    "train_texts = []\n",
    "for story in train_stories:\n",
    "    story_data = raw_text[story].data\n",
    "    if isinstance(story_data, str):\n",
    "        train_texts.append(story_data)\n",
    "    elif isinstance(story_data, (list, np.ndarray)):\n",
    "        train_texts.append(' '.join(str(item) for item in story_data if item))\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot process data for story {story}\")\n",
    "\n",
    "# Initialize the vectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training texts\n",
    "X_bow = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Convert to dense array for inspection\n",
    "X_bow_dense = X_bow.toarray()\n",
    "print(\"Shape of BoW matrix:\", X_bow.shape)\n",
    "print(\"Vocabulary size:\", len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "378b8da5-2811-45f0-86b3-a736d8479987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data_times: <class 'numpy.ndarray'>\n",
      "Length of data_times: 2855\n",
      "First 5 time points: [0.00623583 0.18707483 0.47142857 0.59614512 0.88049887]\n"
     ]
    }
   ],
   "source": [
    "# Check data_times\n",
    "sample_times = sample_data.data_times\n",
    "print(\"Type of data_times:\", type(sample_times))\n",
    "print(\"Length of data_times:\", len(sample_times))\n",
    "print(\"First 5 time points:\", sample_times[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "926c4c77-fb5a-420f-82f1-be62d48f13fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of BoW matrix (time-aligned): (489, 10658)\n"
     ]
    }
   ],
   "source": [
    "def segment_text(data_seq, num_segments):\n",
    "    data = data_seq.data\n",
    "    if isinstance(data, str):\n",
    "        words = data.split()\n",
    "    elif isinstance(data, (list, np.ndarray)):\n",
    "        words = [str(item) for item in data if item]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data format\")\n",
    "    \n",
    "    words_per_segment = len(words) // num_segments\n",
    "    segments = [' '.join(words[i * words_per_segment:(i + 1) * words_per_segment]) \n",
    "                for i in range(num_segments)]\n",
    "    return segments\n",
    "\n",
    "# Segment the first training story\n",
    "segments = segment_text(raw_text[train_stories[0]], 489)\n",
    "\n",
    "# Generate BoW for each time point\n",
    "X_bow_time = vectorizer.transform(segments).toarray()\n",
    "print(\"Shape of BoW matrix (time-aligned):\", X_bow_time.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5de1b477-0087-4a0d-80c5-dc7cf40eeb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bow_time[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719213f-d734-479f-bb89-fc9268b4fd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_214",
   "language": "python",
   "name": "env_214"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
